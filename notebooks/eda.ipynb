{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Document Image Classification - Exploratory Data Analysis\n",
        "\n",
        "This notebook explores the document image classification dataset, which consists of:\n",
        "- Images (TIF format)\n",
        "- OCR text data (TXT files)\n",
        "\n",
        "The goal is to understand the characteristics of the data before building our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os, glob, json, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import cv2\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Configure plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "%matplotlib inline\n",
        "sns.set(font_scale=1.2)\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading\n",
        "\n",
        "First, let's locate our data directories and check the structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Define paths to data directories\n",
        "base_dir = os.path.join('..', 'data')  # Relative to this notebook\n",
        "image_dir = os.path.join(base_dir, 'images')\n",
        "ocr_dir = os.path.join(base_dir, 'ocr')\n",
        "\n",
        "# Check that directories exist\n",
        "print(f\"Image directory exists: {os.path.exists(image_dir)}\")\n",
        "print(f\"OCR directory exists: {os.path.exists(ocr_dir)}\")\n",
        "\n",
        "# List classes (subdirectories)\n",
        "image_classes = sorted([d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))])\n",
        "ocr_classes = sorted([d for d in os.listdir(ocr_dir) if os.path.isdir(os.path.join(ocr_dir, d))])\n",
        "\n",
        "print(f\"\\nImage classes: {image_classes}\")\n",
        "print(f\"OCR classes: {ocr_classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Distribution\n",
        "\n",
        "Let's check how many files we have for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Count files per class\n",
        "image_counts = {cls: len(glob.glob(os.path.join(image_dir, cls, '*.TIF'))) for cls in image_classes}\n",
        "ocr_counts = {cls: len(glob.glob(os.path.join(ocr_dir, cls, '*.TIF.txt'))) for cls in ocr_classes}\n",
        "\n",
        "# Combine and display\n",
        "counts_df = pd.DataFrame({\n",
        "    'Class': list(image_counts.keys()),\n",
        "    'Image Count': list(image_counts.values()),\n",
        "    'OCR Count': [ocr_counts.get(cls, 0) for cls in image_counts.keys()]\n",
        "})\n",
        "display(counts_df)\n",
        "\n",
        "# Check for mismatches\n",
        "mismatch = counts_df[counts_df['Image Count'] != counts_df['OCR Count']]\n",
        "if mismatch.empty:\n",
        "    print(\"No mismatches found - all classes have equal numbers of image and OCR files.\")\n",
        "else:\n",
        "    print(\"Mismatches detected:\")\n",
        "    display(mismatch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sample Loading\n",
        "\n",
        "Let's load a few samples from each class to examine them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_samples(num_per_class=5):\n",
        "    samples = []\n",
        "    for cls in image_classes:\n",
        "        image_files = glob.glob(os.path.join(image_dir, cls, '*.TIF'))[:num_per_class]\n",
        "        for img_path in image_files:\n",
        "            basename = os.path.basename(img_path)\n",
        "            ocr_path = os.path.join(ocr_dir, cls, basename + '.txt')\n",
        "            ocr_text = None\n",
        "            if os.path.exists(ocr_path):\n",
        "                with open(ocr_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                    ocr_text = f.read()\n",
        "            samples.append({'class': cls, 'image_path': img_path, 'ocr_text': ocr_text})\n",
        "    return pd.DataFrame(samples)\n",
        "\n",
        "samples_df = load_samples()\n",
        "print(f\"Loaded {len(samples_df)} samples across {len(samples_df['class'].unique())} classes\")\n",
        "samples_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Image Analysis\n",
        "\n",
        "Let's analyze the characteristics of our image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def analyze_image(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    h, w = img.shape[:2]\n",
        "    channels = 1 if len(img.shape) == 2 else img.shape[2]\n",
        "    return h, w, channels\n",
        "\n",
        "stats = samples_df['image_path'].apply(lambda p: pd.Series(analyze_image(p), index=['height', 'width', 'channels']))\n",
        "samples_df = pd.concat([samples_df, stats], axis=1)\n",
        "\n",
        "print(samples_df[['height', 'width', 'channels']].describe())\n",
        "\n",
        "plt.scatter(samples_df['width'], samples_df['height'], alpha=0.6)\n",
        "plt.xlabel('Width')\n",
        "plt.ylabel('Height')\n",
        "plt.title('Image Dimensions Scatter')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Text Analysis\n",
        "\n",
        "Now let's examine the OCR text data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "samples_df['text_length'] = samples_df['ocr_text'].apply(lambda x: len(x) if x else 0)\n",
        "samples_df['word_count'] = samples_df['ocr_text'].apply(lambda x: len(x.split()) if x else 0)\n",
        "\n",
        "print(samples_df[['text_length', 'word_count']].describe())\n",
        "\n",
        "sns.boxplot(x='word_count', data=samples_df)\n",
        "plt.title('Distribution of Word Counts')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the most common words in each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_common_words(texts, n=20):\n",
        "    words = re.sub(r'[^a-zA-Z\\s]', '', texts.lower()).split()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered = [w for w in words if w not in stop_words and len(w) > 1]\n",
        "    return Counter(filtered).most_common(n)\n",
        "\n",
        "for cls in samples_df['class'].unique():\n",
        "    all_text = ' '.join(samples_df[samples_df['class'] == cls]['ocr_text'].dropna())\n",
        "    print(f\"\\nMost common words for class {cls}:\")\n",
        "    for word, count in get_common_words(all_text):\n",
        "        print(f\"{word}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Further Analysis and Next Steps\n",
        "\n",
        "Fill in observations here after running exploratory steps."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}